{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyterrier as pt\n",
    "import pandas as pd\n",
    "if not pt.java.started():\n",
    "   pt.init()\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_api_url_call(doi, email=\"unpaywall_01@example.com\"):\n",
    "    return f\"https://api.unpaywall.org/v2/{doi}?email={email}\"\n",
    "\n",
    "def extract_pdf_url(res):\n",
    "    res_dict = res.json()\n",
    "\n",
    "    for _, val in res_dict.items():\n",
    "        if isinstance(val, dict):\n",
    "            for k,v in val.items():\n",
    "                if k == \"url_for_pdf\":\n",
    "                    return v\n",
    "    return None\n",
    "\n",
    "def fetch_pdf_url(missing_doi):\n",
    "    try:\n",
    "        # Simulate a short delay\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # Make the API call with a timeout of 15 seconds\n",
    "        res = requests.get(build_api_url_call(missing_doi), timeout=15)\n",
    "        pdf_url = extract_pdf_url(res)\n",
    "        \n",
    "        if pdf_url:\n",
    "            return missing_doi, pdf_url\n",
    "        return missing_doi, None\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(f\"HTTP request timed out for DOI: {missing_doi}\")\n",
    "        return missing_doi, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing DOI {missing_doi}: {e}\")\n",
    "        return missing_doi, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pt.get_dataset('irds:cord19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dois = [row['doi'] for row in dataset.get_corpus_iter()]\n",
    "len(set(all_dois))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = pickle.load(open(\"/workspace/next_pdf_urls.pkl\", \"rb\"))\n",
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_dois = set([doi for doi in all_dois if doi not in urls.keys()])\n",
    "len(missing_dois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_workers = 30\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    # Submit all tasks to the executor\n",
    "    future_to_id = {executor.submit(fetch_pdf_url, missing_doi): missing_doi for missing_doi in missing_dois}\n",
    "    \n",
    "    # Iterate over completed futures with a progress bar\n",
    "    for future in tqdm(as_completed(future_to_id), total=len(missing_dois), desc=\"Processing DOIs\"):\n",
    "        missing_doi = future_to_id[future]\n",
    "        try:\n",
    "            # Wait for the result with a timeout of 15 seconds\n",
    "            missing_doi, pdf_url = future.result(timeout=15)\n",
    "            if pdf_url:\n",
    "                urls[missing_doi] = pdf_url\n",
    "        except TimeoutError:\n",
    "            print(f\"Timeout: DOI {missing_doi} was aborted after 15 seconds.\")\n",
    "            # Optionally attempt to cancel the future (not guaranteed with threads)\n",
    "            future.cancel()\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing DOI {missing_doi}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(urls, open(\"/workspace/next_pdf_urls.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6430242309220109"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "87414/135942"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
