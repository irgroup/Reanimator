{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# We save the model to a local mounted directory\n",
    "os.environ['HF_HOME'] = '/workspace/llm_models'\n",
    "\n",
    "MODEL_NAME=\"gpt-4o-2024-11-20\"\n",
    "\n",
    "modality = \"passage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('/workspace/src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/root/.local/lib/python3.10/site-packages', '/usr/local/lib/python3.10/dist-packages', '/usr/lib/python3/dist-packages', '/workspace/src/']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import dotenv_values, load_dotenv\n",
    "from umbrela.gpt_judge import GPTJudge\n",
    "from umbrela.osllm_judge import OSLLMJudge\n",
    "import logging\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "from collections import defaultdict\n",
    "\n",
    "import pickle\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "from preprocessing.utils import parallel_process_topics, single_process_topics, load_vectorstore, load_pool_documents, parallel_process_topics_new, parallel_process_topics_safe, process_topic\n",
    "\n",
    "db_vals = dotenv_values(\"/workspace/src/.env\")\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load missing_ids from /workspace/src/data/missing_ids/\n",
    "\n",
    "missing_ids_bm25 = json.load(open(\"/workspace/src/data/missing_ids/nan_ids_bm25.json\", \"r\"))\n",
    "missing_ids_vec = json.load(open(\"/workspace/src/data/missing_ids/nan_ids_vectorstore.json\", \"r\"))\n",
    "\n",
    "all_missing_ids = list(missing_ids_bm25['BM25_Text'] + missing_ids_vec['Vectorstore_Text'] +missing_ids_bm25[\"BM25_Table\"] + missing_ids_vec['Vectorstore_Table'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert list to dictionary with topic number as key and docids as list\n",
    "missing_ids_dict = defaultdict(list)\n",
    "\n",
    "for item in all_missing_ids:\n",
    "    missing_ids_dict[f\"{item['topic']}\"].append(item['docid'])\n",
    "\n",
    "missing_pool = dict(missing_ids_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/src/preprocessing/utils.py:87: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding = OpenAIEmbeddings(model=embedding_model)\n",
      "/workspace/src/preprocessing/utils.py:88: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n"
     ]
    }
   ],
   "source": [
    "passage_pool = json.load(open(\"/workspace/src/data/passage_pool.json\", \"r\"))\n",
    "table_pool = json.load(open(\"/workspace/src/data/table_pool.json\", \"r\"))\n",
    "\n",
    "passage_pool_for_rel = json.load(open(\"/workspace/src/data/passage_pool_for_rel.json\", \"r\"))\n",
    "\n",
    "topics = pickle.load(open(\"/workspace/src/data/topics.pkl\", \"rb\"))\n",
    "vectorstore = load_vectorstore(\"/workspace/src/preprocessing/vectorstores/chromadb_store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if modality == 'table':\n",
    "    pool_documents = load_pool_documents(table_pool, vectorstore)\n",
    "elif modality == 'passage':\n",
    "    pool_documents = load_pool_documents(passage_pool, vectorstore)\n",
    "\n",
    "if modality == 'missing':\n",
    "    pool_documents = load_pool_documents(missing_pool, vectorstore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"DEPLOYMENT_NAME\"] = MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    }
   ],
   "source": [
    "judge_gpt = GPTJudge(qrel=\"cord19\", prompt_type=\"bing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = {k:v for k,v in topics.items() if k in pool_documents.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n",
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n",
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n",
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n",
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n",
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n",
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n",
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n",
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n",
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:   2%|▏         | 1/50 [01:53<1:32:47, 113.63s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:   4%|▍         | 2/50 [01:56<38:34, 48.22s/topic]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:   6%|▌         | 3/50 [01:56<20:46, 26.52s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:   8%|▊         | 4/50 [01:58<12:44, 16.62s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  10%|█         | 5/50 [02:00<08:31, 11.36s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  12%|█▏        | 6/50 [02:01<05:48,  7.93s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  14%|█▍        | 7/50 [02:05<04:41,  6.55s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  16%|█▌        | 8/50 [02:06<03:23,  4.85s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  18%|█▊        | 9/50 [02:07<02:29,  3.64s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  20%|██        | 10/50 [02:14<03:08,  4.71s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  22%|██▏       | 11/50 [03:57<22:36, 34.79s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  24%|██▍       | 12/50 [04:00<15:49, 24.98s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  26%|██▌       | 13/50 [04:01<11:02, 17.92s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  28%|██▊       | 14/50 [04:02<07:38, 12.74s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  30%|███       | 15/50 [04:05<05:43,  9.83s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  32%|███▏      | 16/50 [04:05<03:56,  6.97s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  34%|███▍      | 17/50 [04:07<02:56,  5.35s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  36%|███▌      | 18/50 [04:11<02:40,  5.02s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  38%|███▊      | 19/50 [04:13<02:08,  4.14s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  40%|████      | 20/50 [04:23<02:51,  5.71s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  42%|████▏     | 21/50 [05:49<14:31, 30.04s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  44%|████▍     | 22/50 [05:54<10:28, 22.44s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  46%|████▌     | 23/50 [06:01<08:01, 17.84s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  48%|████▊     | 24/50 [06:02<05:29, 12.67s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  50%|█████     | 25/50 [06:02<03:46,  9.05s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  52%|█████▏    | 26/50 [06:06<02:53,  7.24s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  54%|█████▍    | 27/50 [06:10<02:30,  6.56s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  56%|█████▌    | 28/50 [06:18<02:30,  6.84s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  58%|█████▊    | 29/50 [06:19<01:45,  5.01s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  60%|██████    | 30/50 [06:26<01:56,  5.80s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  62%|██████▏   | 31/50 [07:52<09:27, 29.88s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  64%|██████▍   | 32/50 [08:07<07:32, 25.15s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  66%|██████▌   | 33/50 [08:07<05:02, 17.81s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  68%|██████▊   | 34/50 [08:09<03:29, 13.07s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n",
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  72%|███████▏  | 36/50 [08:11<01:45,  7.52s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  74%|███████▍  | 37/50 [08:17<01:31,  7.02s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  76%|███████▌  | 38/50 [08:19<01:07,  5.65s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  78%|███████▊  | 39/50 [08:24<01:02,  5.68s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  80%|████████  | 40/50 [08:33<01:05,  6.51s/topic]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!! Prompt file expects input fields namely: (examples, query, passage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics: 100%|██████████| 50/50 [10:43<00:00, 12.86s/topic]\n"
     ]
    }
   ],
   "source": [
    "all_judgments = parallel_process_topics_safe(topics, pool_documents, judge_gpt, max_workers=10, verbose=False, MODEL_NAME=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passage gpt-4o-2024-11-20\n"
     ]
    }
   ],
   "source": [
    "print(modality, MODEL_NAME) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'/workspace/src/data/qrels_{modality}_pool_{MODEL_NAME.replace(\"/\", \"_\")}.json', 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(all_judgments, json_file, ensure_ascii=False, indent=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
