{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/workspace/src/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first get dois and corresponding full_text\n",
    "\n",
    "from utils import gen_full_text_docling, gen_table\n",
    "import ir_datasets\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dotenv import dotenv_values, load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import Session\n",
    "\n",
    "from database.model import Base, Document, Table\n",
    "from database.chunk_model import Chunk_Base, Chunk\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import langchain_core.documents\n",
    "\n",
    "db_vals = dotenv_values(\"/workspace/src/.env\")\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(f\"postgresql+psycopg2://{db_vals['USER']}:{db_vals['PASSWORD']}@{db_vals['ADDRESS']}:{db_vals['PORT']}/{db_vals['DB']}\", echo=False)\n",
    "session = Session(engine)\n",
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dois = list(set(doi[0] for doi in session.query(Document.doi).all()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1000\n",
    "doi_full_text = {}\n",
    "\n",
    "for i in tqdm(range(0, len(all_dois), BATCH_SIZE)):\n",
    "    batch = all_dois[i:i + BATCH_SIZE]\n",
    "    docs = session.query(Document).filter(Document.doi.in_(batch)).all()\n",
    "    for doc in docs:\n",
    "        doi_full_text[doc.doi] = (doc.title, doc.full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_texts = {}\n",
    "for doi, doc in tqdm(doi_full_text.items()):\n",
    "    full_texts[doi] = gen_full_text_docling(doi_full_text[doi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadatas, texts = [doi for doi in sorted(full_texts.keys())], [full_texts[doi] for doi in sorted(full_texts.keys())]\n",
    "print(len(metadatas), len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,  # chunk size (characters)\n",
    "    chunk_overlap=100,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_docs = [langchain_core.documents.Document(page_content=text, metadata={\"doi\": doi}) for doi, text in full_texts.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_splits = text_splitter.split_documents(lang_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_engine = create_engine(f\"postgresql+psycopg2://{db_vals['USER']}:{db_vals['PASSWORD']}@{db_vals['ADDRESS']}:{db_vals['PORT']}/cord19chunks\", echo=False)\n",
    "chunk_session = Session(chunk_engine)\n",
    "Chunk_Base.metadata.create_all(chunk_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add splits to database\n",
    "cnt = 0\n",
    "for split in tqdm(all_splits):\n",
    "    chunk = Chunk(doi=split.metadata[\"doi\"], chunk_text=split.page_content, chunk_type=\"RCTS_512_100\", modality_type=\"text\")\n",
    "    chunk_session.add(chunk)\n",
    "    cnt += 1\n",
    "    if cnt % 1000 == 0:\n",
    "        chunk_session.commit()\n",
    "chunk_session.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chunk tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_table_dois = list(set(doi[0] for doi in session.query(Table.ir_tab_id).all()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1000\n",
    "doi_table = {}\n",
    "\n",
    "for i in tqdm(range(0, len(all_table_dois), BATCH_SIZE)):\n",
    "    batch = all_table_dois[i:i + BATCH_SIZE]\n",
    "    docs = session.query(Table).filter(Table.ir_tab_id.in_(batch)).all()\n",
    "    for doc in docs:\n",
    "        doi_table[doc.ir_tab_id] = (doc.table_name, doc.header, doc.content, doc.caption, doc.references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_tables = {}\n",
    "for doi, doc in tqdm(doi_table.items()):\n",
    "    full_tables[doi] = gen_table(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=8192,  \n",
    "    chunk_overlap=1000, \n",
    "    add_start_index=True,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadatas_t, texts_t = [doi for doi in sorted(full_tables.keys())], [full_tables[doi] for doi in sorted(full_tables.keys())]\n",
    "print(len(metadatas_t), len(texts_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_tables= [langchain_core.documents.Document(page_content=text, metadata={\"doi\": doi}) for doi, text in full_tables.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_table_splits = table_splitter.split_documents(lang_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for split in tqdm(all_table_splits):\n",
    "    chunk = Chunk(doi=split.metadata[\"doi\"], chunk_text=split.page_content, chunk_type=\"RCTS_8192_1000\", modality_type=\"table\")\n",
    "    chunk_session.add(chunk)\n",
    "    cnt += 1\n",
    "    if cnt % 1000 == 0: \n",
    "        chunk_session.commit()\n",
    "chunk_session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chunk_session.query(Chunk).filter(Chunk.modality_type == \"table\").delete(synchronize_session=False)\n",
    "#chunk_session.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
